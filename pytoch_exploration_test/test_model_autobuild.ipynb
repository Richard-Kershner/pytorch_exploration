{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37213257-b375-41b4-a4e3-07ad83d952c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting initialization\n",
      "python version:  3.8.19 | packaged by conda-forge | (default, Mar 20 2024, 12:38:07) [MSC v.1929 64 bit (AMD64)]\n",
      "numpy version 1.24.4\n",
      "pandas verson:  2.0.3\n",
      "torch version:  2.2.0\n",
      "parent or module directory:  d:\\dev\\pytorch_exploration\\\n",
      "========== initializations ==========\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting initialization\")\n",
    "\n",
    "import sys\n",
    "print(\"python version: \", sys.version)\n",
    "\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "print(\"numpy version\", np.__version__)\n",
    "import pandas as pd\n",
    "print(\"pandas verson: \", pd.__version__)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn # model inheriting\n",
    "import torch.optim as optim\n",
    "print(\"torch version: \", torch.__version__)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# torch setup\n",
    "#device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
    "\n",
    "# ----------------------------- add path and import module (always in parent)\n",
    "from pathlib import Path\n",
    "# Get the current working directory\n",
    "cwd = Path.cwd()\n",
    "\n",
    "# Move up one directory, add to build path \n",
    "parent_dir = str(cwd.parent) + \"\\\\\"\n",
    "sys.path.append(parent_dir)\n",
    "print(\"parent or module directory: \", parent_dir)\n",
    "\n",
    "# import modules\n",
    "from act_bell_relu import Bell_reLU # act_bell_relu.py\n",
    "from model_autobuild import reformat_init_layers\n",
    "from model_autobuild import ModelFromInitLayers\n",
    "\n",
    "print(\"========== initializations ==========\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ab24eff-9510-4e12-b762-400f9972bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     {'outCnt': 3, 'activation': 'input'}\n",
      "in2     {'outCnt': 3, 'activation': 'input'}\n",
      "full_input     {'input': [0, 'in2'], 'activation': 'concat'}\n",
      "A-dense     {'input': 'full_input', 'outCnt': 9, 'activation': 'dense'}\n",
      "A-bell_reLu     {'input': 'full_input', 'activation': Bell_reLU()}\n",
      "A-reLu     {'input': 'full_input', 'activation': ReLU()}\n",
      "B-concat_A     {'input': ['A-dense', 'A-bell_reLu', 'A-reLu'], 'activation': 'concat'}\n",
      "B-dense     {'input': 'B-concat_A', 'outCnt': 9, 'activation': 'dense'}\n",
      "C-out_dense     {'input': 'B-dense', 'outCnt': 9, 'activation': 'dense'}\n",
      "\n",
      "0     {'outCnt': 3, 'activation': 'input', 'tensor': tensor([0., 0., 0.])}\n",
      "in2     {'outCnt': 3, 'activation': 'input', 'tensor': tensor([0., 0., 0.])}\n",
      "full_input     {'input': [0, 'in2'], 'activation': 'concat', 'outCnt': 6, 'tensor': tensor([0., 0., 0., 0., 0., 0.])}\n",
      "A-dense     {'input': 'full_input', 'outCnt': 9, 'activation': Linear(in_features=6, out_features=9, bias=True), 'tensor': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n",
      "A-bell_reLu     {'input': 'full_input', 'activation': Bell_reLU(), 'outCnt': 6, 'tensor': tensor([0., 0., 0., 0., 0., 0.])}\n",
      "A-reLu     {'input': 'full_input', 'activation': ReLU(), 'outCnt': 6, 'tensor': tensor([0., 0., 0., 0., 0., 0.])}\n",
      "B-concat_A     {'input': ['A-dense', 'A-bell_reLu', 'A-reLu'], 'activation': 'concat', 'outCnt': 21, 'tensor': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n",
      "B-dense     {'input': 'B-concat_A', 'outCnt': 9, 'activation': Linear(in_features=21, out_features=9, bias=True), 'tensor': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n",
      "C-out_dense     {'input': 'B-dense', 'outCnt': 9, 'activation': Linear(in_features=9, out_features=9, bias=True), 'tensor': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================ testing auto build =======================\n",
    "\n",
    "# ----- definining layers in\n",
    "#          activation on all can be \"input\", \"dense\", \"concat\" or specific activation formula\n",
    "#          input is a pointer to the key of the key value of the source\n",
    "#          outCnt is the number of outputs which is also the size of the tensor\n",
    "\n",
    "init_layers = {\n",
    "      0 : {\"outCnt\": 3, \"activation\":\"input\"} # inputLayer... 0 denotes if multiple inputs, first\n",
    "    ,\"in2\" : {\"outCnt\": 3, \"activation\":\"input\"}\n",
    "    ,\"full_input\" : {\"input\":[0,\"in2\"], \"activation\":\"concat\"}\n",
    "    , \"A-dense\" : {\"input\":\"full_input\", \"outCnt\":9, \"activation\":\"dense\"}\n",
    "    , \"A-bell_reLu\" : {\"input\":\"full_input\", \"activation\":Bell_reLU()}\n",
    "    , \"A-reLu\" : {\"input\":\"full_input\", \"activation\":nn.ReLU()}\n",
    "    , \"B-concat_A\" : {\"input\":[\"A-dense\",\"A-bell_reLu\", \"A-reLu\"], \"activation\":\"concat\"}\n",
    "    , \"B-dense\": {\"input\":\"B-concat_A\", \"outCnt\":9, \"activation\":\"dense\"}\n",
    "    , \"C-out_dense\": {\"input\":\"B-dense\", \"outCnt\":9, \"activation\":\"dense\"}\n",
    "}\n",
    "\n",
    "# ---- input_layers and output layers, pointers to the layer key, need to be supplied.\n",
    "#          current format requires an array\n",
    "input_layers = [0, \"in2\"]\n",
    "output_layers = [\"C-out_dense\"]\n",
    "\n",
    "# ---- Display layers for testing purposes\n",
    "for key, value in init_layers.items():\n",
    "    print(key, \"   \", value)\n",
    "print()\n",
    "\n",
    "# ----- reformat layers to the needed setup\n",
    "#           creates activations as needed\n",
    "#           Fills in outCnt activation and concat layers\n",
    "\n",
    "init_layers = reformat_init_layers(init_layers)\n",
    "\n",
    "# ---- Display final layers for review and testing purposes\n",
    "for key, value in init_layers.items():\n",
    "    print(key, \"   \", value)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b0038a3-85cf-4c38-a534-d750713844ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Create the model from the reformatted layers\n",
    "model = ModelFromInitLayers(init_layers, input_layers, output_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "641aa144-dc65-4842-b3e4-38d30d15e8d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensors\n",
      "0   tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64)\n",
      "in2   tensor([0.4000, 0.5000, 0.6000], dtype=torch.float64)\n",
      "full_input   tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000], dtype=torch.float64)\n",
      "A-dense   tensor([-0.3600, -0.1939, -0.2156,  0.1106, -0.1993, -0.2029, -0.1020, -0.0887,\n",
      "        -0.0261], dtype=torch.float64, grad_fn=<ViewBackward0>)\n",
      "A-bell_reLu   tensor([0.9992, 0.9989, 0.9986, 0.9982, 0.9976, 0.9969], dtype=torch.float64)\n",
      "A-reLu   tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000], dtype=torch.float64)\n",
      "B-concat_A   tensor([-0.3600, -0.1939, -0.2156,  0.1106, -0.1993, -0.2029, -0.1020, -0.0887,\n",
      "        -0.0261,  0.9992,  0.9989,  0.9986,  0.9982,  0.9976,  0.9969,  0.1000,\n",
      "         0.2000,  0.3000,  0.4000,  0.5000,  0.6000], dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "B-dense   tensor([-0.4320,  0.2815,  0.1656, -0.2405,  0.1781,  0.2521, -0.7841, -0.7757,\n",
      "         0.1744], dtype=torch.float64, grad_fn=<ViewBackward0>)\n",
      "C-out_dense   tensor([ 0.2440,  0.2423, -0.2939,  0.2621, -0.3364, -0.2565,  0.5393,  0.6541,\n",
      "         0.5016], dtype=torch.float64, grad_fn=<ViewBackward0>)\n",
      "\n",
      " output from layers-> ['C-out_dense'] \n",
      "\n",
      "=============== [0.1 0.2 0.3]\n",
      "=============== [0.4 0.5 0.6]\n",
      ">>>> tensor([ 0.2440,  0.2423, -0.2939,  0.2621, -0.3364, -0.2565,  0.5393,  0.6541,\n",
      "         0.5016], dtype=torch.float64, grad_fn=<ViewBackward0>)\n",
      "\n",
      " tensors\n",
      "0   tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64)\n",
      "in2   tensor([0.4000, 0.5000, 0.6000], dtype=torch.float64)\n",
      "full_input   tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000], dtype=torch.float64)\n",
      "A-dense   tensor([-0.3600, -0.1939, -0.2156,  0.1106, -0.1993, -0.2029, -0.1020, -0.0887,\n",
      "        -0.0261], dtype=torch.float64, grad_fn=<ViewBackward0>)\n",
      "     w: OrderedDict([('weight', tensor([[-3.8288e-01, -2.6109e-01, -3.4064e-02,  1.0397e-01, -3.3552e-01,\n",
      "         -2.0142e-01],\n",
      "        [-2.9472e-01, -3.5623e-01,  3.6819e-03, -1.4657e-01, -4.0742e-01,\n",
      "          1.4756e-01],\n",
      "        [-1.0993e-01,  2.5286e-04,  5.7818e-03, -4.0586e-01, -2.1456e-01,\n",
      "         -1.5279e-01],\n",
      "        [-1.3821e-01,  1.9362e-01, -3.6560e-01,  3.3458e-01,  1.2429e-02,\n",
      "         -3.2265e-02],\n",
      "        [ 9.6978e-02, -2.8909e-02, -2.3363e-01, -2.8441e-01, -2.5833e-01,\n",
      "          3.7022e-01],\n",
      "        [-1.9182e-01,  3.9545e-01,  1.5584e-01, -4.4053e-02,  1.5753e-01,\n",
      "         -3.3409e-01],\n",
      "        [-8.1189e-02, -1.0788e-01, -1.7207e-01,  4.0647e-01, -2.9672e-01,\n",
      "          9.8123e-03],\n",
      "        [-3.6037e-01, -1.4369e-01, -1.2323e-01, -1.3522e-01, -2.1547e-01,\n",
      "          3.1301e-01],\n",
      "        [ 1.8610e-02,  9.3657e-03, -2.3916e-01,  3.4832e-01, -7.4365e-02,\n",
      "          1.0496e-01]], dtype=torch.float64)), ('bias', tensor([-0.0122,  0.0795,  0.1549,  0.0747, -0.1123, -0.1703, -0.0408, -0.0130,\n",
      "        -0.1232], dtype=torch.float64))])\n",
      "A-bell_reLu   tensor([0.9992, 0.9989, 0.9986, 0.9982, 0.9976, 0.9969], dtype=torch.float64)\n",
      "A-reLu   tensor([0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000], dtype=torch.float64)\n",
      "B-concat_A   tensor([-0.3600, -0.1939, -0.2156,  0.1106, -0.1993, -0.2029, -0.1020, -0.0887,\n",
      "        -0.0261,  0.9992,  0.9989,  0.9986,  0.9982,  0.9976,  0.9969,  0.1000,\n",
      "         0.2000,  0.3000,  0.4000,  0.5000,  0.6000], dtype=torch.float64,\n",
      "       grad_fn=<CatBackward0>)\n",
      "B-dense   tensor([-0.4320,  0.2815,  0.1656, -0.2405,  0.1781,  0.2521, -0.7841, -0.7757,\n",
      "         0.1744], dtype=torch.float64, grad_fn=<ViewBackward0>)\n",
      "     w: OrderedDict([('weight', tensor([[-0.1123,  0.1918, -0.0557, -0.0266,  0.1903, -0.0301,  0.0745, -0.0654,\n",
      "         -0.1269, -0.0561, -0.0341, -0.1078, -0.0198, -0.0735,  0.1625,  0.2174,\n",
      "         -0.1247, -0.2179, -0.0682, -0.1744,  0.0690],\n",
      "        [-0.1669,  0.0313,  0.0077,  0.1942,  0.1605, -0.0792, -0.1919,  0.1885,\n",
      "          0.0327, -0.0730,  0.0814,  0.0918, -0.0954,  0.0226,  0.1125,  0.0229,\n",
      "         -0.0077,  0.0342,  0.1213, -0.0368, -0.1541],\n",
      "        [-0.0600, -0.1379, -0.1461, -0.0742,  0.1192, -0.1589,  0.2058, -0.2078,\n",
      "          0.0003, -0.0649, -0.1173, -0.0023, -0.0927,  0.1948,  0.1331, -0.1659,\n",
      "         -0.1585,  0.0089, -0.0222, -0.0626, -0.0040],\n",
      "        [-0.0180, -0.0076, -0.0386,  0.1659,  0.1004,  0.1061,  0.1205,  0.0540,\n",
      "          0.0657, -0.0177, -0.1368,  0.1096, -0.0910,  0.0847,  0.0257, -0.0538,\n",
      "          0.0583, -0.1068, -0.0986, -0.0385,  0.1517],\n",
      "        [ 0.0162,  0.1596,  0.0456, -0.0196, -0.0693, -0.1331,  0.1673, -0.0294,\n",
      "         -0.0187, -0.0941, -0.0802,  0.0837,  0.1825, -0.0975,  0.0692, -0.0632,\n",
      "         -0.1772,  0.2113,  0.2064,  0.0132, -0.1980],\n",
      "        [-0.0264, -0.2019, -0.2135, -0.1971, -0.0194,  0.0891,  0.2035,  0.1038,\n",
      "          0.1313, -0.1691, -0.1000,  0.1915,  0.1063,  0.1833,  0.1650,  0.0328,\n",
      "          0.0805,  0.0616, -0.1774, -0.1635, -0.1192],\n",
      "        [-0.2139, -0.0750, -0.1987, -0.1299,  0.0934,  0.0752,  0.1868,  0.1026,\n",
      "         -0.1335, -0.1814,  0.0246, -0.1596, -0.0514, -0.1108,  0.0549, -0.0413,\n",
      "          0.0099,  0.1787, -0.1655, -0.1892, -0.1953],\n",
      "        [ 0.1791, -0.2032,  0.0487,  0.0686, -0.0732, -0.2001, -0.0367, -0.1948,\n",
      "         -0.0203, -0.0644, -0.1569, -0.2133, -0.0245, -0.0958, -0.0454, -0.1001,\n",
      "         -0.0800, -0.1526,  0.1354,  0.0376, -0.1713],\n",
      "        [-0.0803,  0.1997,  0.1384,  0.0747, -0.0495, -0.0513,  0.2123,  0.1174,\n",
      "         -0.2089,  0.1726, -0.0371, -0.1562,  0.2059, -0.0261,  0.1618, -0.0239,\n",
      "          0.0828,  0.0055,  0.1300, -0.0366, -0.2078]], dtype=torch.float64)), ('bias', tensor([-0.1435,  0.1333,  0.1261, -0.1957,  0.1446,  0.0373, -0.1960, -0.1235,\n",
      "        -0.0329], dtype=torch.float64))])\n",
      "C-out_dense   tensor([ 0.2440,  0.2423, -0.2939,  0.2621, -0.3364, -0.2565,  0.5393,  0.6541,\n",
      "         0.5016], dtype=torch.float64, grad_fn=<ViewBackward0>)\n",
      "     w: OrderedDict([('weight', tensor([[-0.0526,  0.3087, -0.2770,  0.2112, -0.0207,  0.0689, -0.2225, -0.3205,\n",
      "          0.1615],\n",
      "        [ 0.0732, -0.1674,  0.1012,  0.2571, -0.0577, -0.1054,  0.2213, -0.3221,\n",
      "          0.1416],\n",
      "        [ 0.0114, -0.0898, -0.0613,  0.0342,  0.0377, -0.0696, -0.0405,  0.3074,\n",
      "          0.1519],\n",
      "        [ 0.0075,  0.2601,  0.2935,  0.1027,  0.2646, -0.2226,  0.1909, -0.1752,\n",
      "         -0.2453],\n",
      "        [-0.2811, -0.0303,  0.0369,  0.3183, -0.0093, -0.2463,  0.0721,  0.3032,\n",
      "         -0.0621],\n",
      "        [ 0.3277,  0.1864, -0.2990, -0.1521,  0.1650,  0.3106,  0.2224,  0.0137,\n",
      "         -0.0777],\n",
      "        [ 0.1383, -0.1929,  0.1485,  0.1120, -0.0406, -0.1575, -0.2777, -0.2432,\n",
      "          0.2176],\n",
      "        [-0.0129,  0.3299, -0.3107,  0.3331, -0.1080, -0.1131, -0.2865, -0.2796,\n",
      "          0.1491],\n",
      "        [-0.1699,  0.1617,  0.1008, -0.1307, -0.1890, -0.0093, -0.1326,  0.0314,\n",
      "          0.1147]], dtype=torch.float64)), ('bias', tensor([-0.2338,  0.3020, -0.0543,  0.2337, -0.0125, -0.0636,  0.2582,  0.2675,\n",
      "         0.2710], dtype=torch.float64))])\n"
     ]
    }
   ],
   "source": [
    "# ==== test forward running the model\n",
    "\n",
    "print(\"tensors\")\n",
    "for name, layer in model.layers.items():\n",
    "    print(name, \" \", layer[\"tensor\"])\n",
    "\n",
    "data = np.array([[.1,.2,.3],[.4,.5,.6]])\n",
    "print(\"\\n output from layers->\", model.output_layers, \"\\n\")\n",
    "Y = model.forward(data)\n",
    "for y in Y:\n",
    "    # print tensor converted to numpy\n",
    "    print(\">>>>\", y) # crashes when gradient?  torch.Tensor.numpy(y) )\n",
    "\n",
    "print(\"\\n\", \"tensors\")\n",
    "for name, layer in model.layers.items():\n",
    "    print(name, \" \", layer[\"tensor\"])\n",
    "    # ---- for the dense layers - show the weights.  \n",
    "    if type(layer[\"activation\"]) == torch.nn.Linear:\n",
    "        print(\"     w:\", layer[\"activation\"].state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befef7a9-1fd2-438f-beea-bfaf9a90d9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
